{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7028988b-a025-4ad4-bbba-03c2bca96227",
   "metadata": {},
   "source": [
    "# Fake News Detection Powered with BERT and Friends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68add221-13cc-423b-911f-6db6df2d8356",
   "metadata": {},
   "source": [
    "- https://medium.com/@vslovik/fake-news-detection-empowered-with-bert-and-friends-20397f7e1675<br>\n",
    "\n",
    ">- https://github.com/UKPLab/coling2018_fake-news-challenge/blob/master/data/fnc-1/corpora/FNC_ARC/combined_bodies_train.csv<br>\n",
    ">- https://github.com/FakeNewsChallenge/fnc-1<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276159b-57b9-4f95-85c5-e4e4dc279b66",
   "metadata": {},
   "source": [
    "### BERT\n",
    "BERT (Devlin et al., 2018), which stands for <b>B</b>idirectional <b>E</b>ncoder <b>R</b>epresentations from <b>T</b>ransformers, is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. BERT uses the ”masked language model” (MLM) pre-training objective, inspired by the Cloze task (Taylor, 1953). The masked language model randomly masks some of the tokens from the input, and the objective is to predict the masked word based on its context. In addition to the masked language model, BERT also uses a ”next sentence prediction” (NSP) task that jointly pre-trains text-pair representations.\n",
    "\n",
    "For the pre-training corpus (Devlin et al., 2018) use the BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
    "\n",
    "The self-attention mechanism in the Transformer allows BERT to model many downstream tasks — whether they involve single text or text pairs. For each task, the steps are: (1) simply plug in the task-specific inputs and outputs into\n",
    "BERT and (2) fine-tune all the parameters end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ad76d-b927-4588-9b41-6b4ccb8db4af",
   "metadata": {},
   "source": [
    "XLNet\n",
    "BERT predicts all masked positions independently, meaning that during the training, it does not learn to handle dependencies between predicted masked tokens. This reduces the number of dependencies BERT learns at once, making the learning signal weaker than it could be.\n",
    "Another problem with BERT is that the [MASK] token — which is at the center of training BERT — never appears when fine-tuning BERT on downstream tasks. That means that the [MASK] token is a source of train-test skew while\n",
    "fine-tuning.\n",
    "XLNet (Yang et al., 2019) incorporates a bidirectional context while avoiding the [MASK] tokens and independent predictions. It does this by introducing ”permutation language modeling”: instead of predicting the tokens in sequential order, it predicts tokens in some random order.\n",
    "Aside from using permutation language modeling, XLNet improves upon BERT by using the Transformer XL as its base architecture.\n",
    "Both BERT and XLNet can take the pair of text sequences as an input. To enable the model to distinguish between words in two different segments, BERT learns a segment embedding. In contrast, XLNet learns an embedding that represents whether two words are from the same segment. This embedding is used during attention computation between any two words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852579d-26be-4994-a43a-a27d377c0f40",
   "metadata": {},
   "source": [
    "### RoBERTa\n",
    "(Liu et al., 2019) found that BERT was significantly under-trained and proposed an improved recipe for training BERT models, which they call RoBERTa (Robustly optimized BERT approach), that can match or exceed the performance of all of the post-BERT methods. The recipe includes: (1) training the model longer, with bigger batches, over more data; (2) removing the ”next sentence prediction” objective; (3) training on longer sequences; and (4) dynamically changing the masking pattern applied to the training data.\n",
    "\n",
    "To train RoBERTa (Liu et al., 2019) use five English-language corpora of varying sizes and domains, totaling over 160GB of uncompressed text. They also demonstrate that removing the ”next sentence prediction” loss together with segment-pair input format matches or slightly improves downstream task performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315146d-3676-4634-ba22-1656720df712",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fake News Detection\n",
    "For our experiments on fine-tuning transformers on the FNC-1 task, we use the Simple Transformers (Rajapakse, 2019) wrapper around Hugging Face Transformers library (Wolf et al., 2019b).\n",
    "\n",
    "The model implementations provided in the library are tested to ensure they match the original author implementations’ performances on various benchmarks. A list of architectures for which reference implementations and pre-trained weights are currently provided in Transformers includes BERT, XLNet, and RoBERTa, as well as DistilBERT, GPT and GPT2.\n",
    "\n",
    "The Simple Transformers (Rajapakse, 2019) library is built on top of the Hugging Face Transformers. The idea behind it was to make it as simple as possible, abstracting a lot of the implementation details.\n",
    "Thus, with Simple Transformers on the shoulders of Hugging Face Transformers, we could access pre-trained BERT, XLNet, and RoBERTa in a unified way without a lot of pre-processing coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f3e9f-f707-485f-9ca5-aa87f01c14ba",
   "metadata": {},
   "source": [
    "Let us first prepare the data to feed into transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbd884f-f9fa-4570-bbf1-ae497025a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to determine the device handle for GPU 0000:01:00.0: GPU is lost.  Reboot the system to recover this GPU\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b33622f-09b7-4e55-b6ee-0f966d9231f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fnc(path_headlines, path_bodies):\n",
    "\n",
    "    map = {'agree': 0, 'disagree':1, 'discuss':2, 'unrelated':3}\n",
    "\n",
    "    with open(path_bodies, encoding='utf_8') as fb:  # Body ID,articleBody\n",
    "        body_dict = {}\n",
    "        lines_b = csv.reader(fb)\n",
    "        for i, line in enumerate(tqdm(list(lines_b), ncols=80, leave=False)):\n",
    "            if i > 0:\n",
    "                body_id = int(line[0].strip())\n",
    "                body_dict[body_id] = line[1]\n",
    "\n",
    "    with open(path_headlines, encoding='utf_8') as fh: # Headline,Body ID,Stance\n",
    "        lines_h = csv.reader(fh)\n",
    "        h = []\n",
    "        b = []\n",
    "        l = []\n",
    "        for i, line in enumerate(tqdm(list(lines_h), ncols=80, leave=False)):\n",
    "            if i > 0:\n",
    "                body_id = int(line[1].strip())\n",
    "                label = line[2].strip()\n",
    "                if label in map and body_id in body_dict:\n",
    "                    h.append(line[0])\n",
    "                    l.append(map[line[2]])\n",
    "                    b.append(body_dict[body_id])\n",
    "    return h, b, l\n",
    "\n",
    "data_dir = '/programing/programing_created-acer/fnc-1/fnc-1'\n",
    "headlines, bodies, labels = fnc(\n",
    "    os.path.join(data_dir, 'train_stances.csv'),\n",
    "    os.path.join(data_dir, 'train_bodies.csv')\n",
    ")\n",
    "\n",
    "list_of_tuples = list(zip(headlines, bodies, labels))\n",
    "df = pd.DataFrame(list_of_tuples, columns=['text_a', 'text_b', 'labels'])\n",
    "train_df, val_df = train_test_split(df)\n",
    "labels_val = pd.Series(val_df['labels']).to_numpy()\n",
    "\n",
    "headlines, bodies, labels = fnc(\n",
    "    os.path.join(data_dir, 'competition_test_stances.csv'),\n",
    "    os.path.join(data_dir, 'competition_test_bodies.csv')\n",
    ")\n",
    "\n",
    "list_of_tuples = list(zip(headlines, bodies, labels))\n",
    "test_df = pd.DataFrame(list_of_tuples, columns=['text_a', 'text_b', 'labels'])\n",
    "labels_test = pd.Series(test_df['labels']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc111ba3-b076-4648-a97f-a45844d2e6ad",
   "metadata": {},
   "source": [
    "Then we create the instance on the Transformer model with Simple Transformers and train it. The *<font>TransformerModel</font>* constructor takes two parameters: model type and model name. All available model types and model names are listed on the Simple Transformers GitHub page: https://github.com/ThilinaRajapakse/simpletransformers.\n",
    "\n",
    "We use *<font>`bert/bert-base-uncased`<font>*, *<font>`xlnet/xlnet-base-cased`<font>*, and *<font>`roberta/roberta-base`<font>* models. We set the learning rate to be 3e-5 for BERT and 1e-5 for XLNet and RoBERTa. (Use the validation set for the best hyper-parameters search.)\n",
    "\n",
    "Let’s set maximum sequence length to be equal to 512 tokens: the maximum possible value to set given the parameters of pre-trained models, and the number of epoch to fine-tune the transformer to be 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90813134-98a6-45e9-8515-8f2cbe7b88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # grid, random\n",
    "    \"metric\": {\"name\": \"train_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"min\": 1e-5, \"max\": 2e-5},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Simple Sweep\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c09d9b-0d36-4450-a60c-331582b2215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.model import TransformerModel\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "def train():\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init()\n",
    "\n",
    "    # Create a TransformerModel\n",
    "    model = TransformerModel('roberta', 'roberta-base', num_labels=4, sweep_config=wandb.config, args={\n",
    "        'learning_rate':1e-5,\n",
    "        'num_train_epochs': 1,\n",
    "        'reprocess_input_data': True,\n",
    "        'overwrite_output_dir': True,\n",
    "        'process_count': 10,\n",
    "        'train_batch_size': 1,\n",
    "        'eval_batch_size': 1,\n",
    "        'max_seq_length': 32,\n",
    "        'fp16': True,\n",
    "        'gradient_accumulation_steps': 1,\n",
    "        'tensorboard_dir': '/programing/programing_created-acer/fnc-1/train_',\n",
    "        'wandb_project': 'fnc_roberta',\n",
    "        'evaluate_during_training': True,\n",
    "        'manual_seed': 4,\n",
    "        'use_multiprocessing': True\n",
    "    })\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(train_df, eval_df=test_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval_model(test_df)\n",
    "\n",
    "    # Sync wandb\n",
    "    wandb.join()\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caba16c-3d1b-48d2-86de-9fbe9fe9c9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from simpletransformers.model import TransformerModel\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import wandb\n",
    "\n",
    "wandb.init()\n",
    "model = TransformerModel('roberta', 'roberta-base', num_labels=4, args={\n",
    "    'learning_rate':1e-5,\n",
    "    'num_train_epochs': 5,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'process_count': 10,\n",
    "    'train_batch_size': 1,\n",
    "    'eval_batch_size': 4,\n",
    "    'max_seq_length': 256,\n",
    "    'fp16': True,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'tensorboard_dir': '/programing/programing_created-acer/fnc-1/train_',\n",
    "    'wandb_project': 'fnc_roberta'\n",
    "})\n",
    "\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfede39-c8c7-4d77-8524-6a3b2c4db4a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "BERT model fine-tuned, now we get predictions on the test set and evaluate fine-tuning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bf994-6602-421e-bf4d-7b5cfff370e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cd2c7daa1f4466b5683ab9a9bdc521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "_, model_outputs_test, _ = model.eval_model(test_df)\n",
    "\n",
    "preds_test = np.argmax(model_outputs_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63187b8-5809-418c-a486-fabd2cea6cfa",
   "metadata": {},
   "source": [
    "Then we calculate averaged and class-wise F1 scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8daa56-bc58-4896-b471-dd7b80f331b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_f1_scores(y_true, y_predicted):\n",
    "    f1_macro = f1_score(y_true, y_predicted, average='macro')\n",
    "    f1_classwise = f1_score(y_true, y_predicted, average=None, labels=[0, 1, 2, 3])\n",
    "\n",
    "    resultstring = \"F1 macro: {:.3f}\".format(f1_macro * 100) + \"% \\n\"\n",
    "    resultstring += \"F1 agree: {:.3f}\".format(f1_classwise[0] * 100) + \"% \\n\"\n",
    "    resultstring += \"F1 disagree: {:.3f}\".format(f1_classwise[1] * 100) + \"% \\n\"\n",
    "    resultstring += \"F1 discuss: {:.3f}\".format(f1_classwise[2] * 100) + \"% \\n\"\n",
    "    resultstring += \"F1 unrelated: {:.3f}\".format(f1_classwise[3] * 100) + \"% \\n\"\n",
    "\n",
    "    return resultstring\n",
    "\n",
    "calculate_f1_scores(preds_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08370605-20f5-41e9-9d91-4ce5c016dea3",
   "metadata": {},
   "source": [
    "After that we can calculate FNC-1 (the metric proposed by FNC-1 organizers) and print the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2e9bb-d178-497d-8165-98dad3244599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS = [0, 1, 2, 3]\n",
    "RELATED = [0, 1, 2]\n",
    "\n",
    "def print_confusion_matrix(cm):\n",
    "    lines = ['CONFUSION MATRIX:']\n",
    "    header = \"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format('', *LABELS)\n",
    "    line_len = len(header)\n",
    "    lines.append(\"-\"*line_len)\n",
    "    lines.append(header)\n",
    "    lines.append(\"-\"*line_len)\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i, row in enumerate(cm):\n",
    "        hit += row[i]\n",
    "        total += sum(row)\n",
    "        lines.append(\"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format(LABELS[i], *row))\n",
    "        lines.append(\"-\"*line_len)\n",
    "    lines.append(\"ACCURACY: {:.3f}\".format((hit / total)*100) + \"%\")\n",
    "    print('\\n'.join(lines))\n",
    "\n",
    "def fnc_score_cm(predicted_labels, target):\n",
    "    score = 0.0\n",
    "    cm = [[0, 0, 0, 0],\n",
    "          [0, 0, 0, 0],\n",
    "          [0, 0, 0, 0],\n",
    "          [0, 0, 0, 0]]\n",
    "    for i, (g, t) in enumerate(zip(predicted_labels, target)):\n",
    "            if g == t:\n",
    "                score += 0.25\n",
    "                if g != 3:\n",
    "                    score += 0.50\n",
    "            if g in RELATED and t in RELATED:\n",
    "                score += 0.25\n",
    "\n",
    "            cm[g][t] += 1\n",
    "    return score,  cm\n",
    "\n",
    "fnc_score, cm_test = fnc_score_cm(preds_test, labels_test)\n",
    "print(\"\\nRelative FNC Score: {:.3f}\".format(100/13204.75*fnc_score) + \"% \\n\")\n",
    "print_confusion_matrix(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92c91d-bb38-4099-8917-1ce9b8ce08fe",
   "metadata": {},
   "source": [
    "Let’s calculate class-wise precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c6eac-0016-4b88-867e-69a713ad217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "eval_report = classification_report(labels_test, preds_test, target_names=LABELS)\n",
    "print('Test report', eval_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5b339-578a-405e-b766-15027bd482cb",
   "metadata": {},
   "source": [
    "### Add by Me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4f190-820e-4ce1-9e27-f599c17e9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LABELS)\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750bc85-b193-4273-adc9-05243233f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(preds_test, labels_test)\n",
    "print(fpr, tpr, threshold)\n",
    "\n",
    "auc1 = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc1)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b08d39-1804-4d07-97d2-54d2252c8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_roberta_0110.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab216b39-072e-4331-af12-cf38bc0eef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9913b77cba1d4846ac4b42368bd44f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea0b36a3f3249e79ac00510a1939789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict_data = pd.read('')\n",
    "predictions, raw_outputs = model.predict([[\"aaa\", \"bbb\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e60f0b1b-fe92-4c57-ad17-871bca428572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65429688, -0.94433594, -0.08044434,  2.04296875]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a9a57-8d54-4379-a95d-37158ca2bed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423db80-1b5f-490d-bb7e-3feec1d3e7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d79b57-72c4-4034-ace8-3e25f35acbfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9ca8f894ccbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/programing/programing_created-acer/fnc-1/fnc-1/fnc_roberta_0116_general4.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    726\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflowgpuenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    136\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/programing/programing_created-acer/fnc-1/fnc-1/fnc_roberta_0116_general4.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0b2702-3108-44ae-8175-508c0e5b5671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<simpletransformers.classification.classification_model.ClassificationModel at 0x25c17a65070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63ce53c-631b-422c-9fd8-9f750de2f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/programing/programing_created-acer/fnc-1/my_dataset/buzzfeed/buzzfeed_preds3.csv', index_col=0, encoding='utf-8')\n",
    "\n",
    "preds = []\n",
    "temp = []\n",
    "for i in range(len(data)):\n",
    "    temp = []\n",
    "    temp.append(data.loc[i,'post2'])\n",
    "    temp.append(data.loc[i,'article'])\n",
    "    preds.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4373758-b3bf-4c2a-ac7f-e56114e33758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1344ea906544b0d871de42dbf636d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd9bab6d9d1471eb21f51a4e7fbf2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad45ebf-1f30-4c7e-9a54-540085ada96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7b99ed1af33d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9699bb88-a2da-4754-a683-4a7a51039069",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be509913-adbd-48e1-9007-b71fd91bae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agree: 304/Disagree: 27/Discuss: 86/Unrelated: 49\n"
     ]
    }
   ],
   "source": [
    "agree = 0\n",
    "disagree = 0\n",
    "discuss = 0\n",
    "unrelated = 0\n",
    "for i in predictions:\n",
    "    if i == 0:\n",
    "        agree += 1\n",
    "    elif i == 1:\n",
    "        disagree += 1\n",
    "    elif i == 2:\n",
    "        discuss += 1\n",
    "    elif i == 3:\n",
    "        unrelated += 1\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "print(f'Agree: {agree}/Disagree: {disagree}/Discuss: {discuss}/Unrelated: {unrelated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81ebd628-e941-4282-877b-eeda259384a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world :)\n",
      "hello world :)\n",
      "hello world :)\n",
      "hello world :)\n"
     ]
    }
   ],
   "source": [
    "# 引入套件\n",
    "import tkinter as tk\n",
    "\n",
    "# 建立主視窗和 Frame（把元件變成群組的容器）\n",
    "window = tk.Tk()\n",
    "top_frame = tk.Frame(window)\n",
    "\n",
    "# 將元件分為 top/bottom 兩群並加入主視窗\n",
    "top_frame.pack()\n",
    "bottom_frame = tk.Frame(window)\n",
    "bottom_frame.pack(side=tk.BOTTOM)\n",
    "\n",
    "# 建立事件處理函式（event handler），透過元件 command 參數存取\n",
    "def echo_hello():\n",
    "    print('hello world :)')\n",
    "\n",
    "# 以下為 top 群組\n",
    "left_button = tk.Button(top_frame, text='Red', fg='red')\n",
    "# 讓系統自動擺放元件，預設為由上而下（靠左）\n",
    "left_button.pack(side=tk.LEFT)\n",
    "\n",
    "middle_button = tk.Button(top_frame, text='Green', fg='green')\n",
    "middle_button.pack(side=tk.LEFT)\n",
    "\n",
    "right_button = tk.Button(top_frame, text='Blue', fg='blue')\n",
    "right_button.pack(side=tk.LEFT)\n",
    "\n",
    "# 以下為 bottom 群組\n",
    "# bottom_button 綁定 echo_hello 事件處理，點擊該按鈕會印出 hello world :)\n",
    "bottom_button = tk.Button(bottom_frame, text='Black', fg='black', command=echo_hello)\n",
    "# 讓系統自動擺放元件（靠下方）\n",
    "bottom_button.pack(side=tk.BOTTOM)\n",
    "\n",
    "# 運行主程式\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1781111-02fa-479f-be69-bef254d56c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/programing/programing_created-acer/fnc-1/train_/fnc_roberta_0115_self1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9289fc33-d288-4ebd-9294-04d9f6604326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c10b8c6a69846f4a50149c7c24d1adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf10e574864593889c0805546ad166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c867bded7e4dad8940123bbe8290a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eca2a17e6c4e18a5d850683c58a21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import math\n",
    "from simpletransformers.model import TransformerModel\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title('2022TISF-190026')\n",
    "window.geometry('1200x800')\n",
    "window.configure(background='white')\n",
    "\n",
    "def calculate_bmi_number():\n",
    "    height = str(height_entry.get())\n",
    "    weight = str(weight_entry.get())\n",
    "    \n",
    "    with open('D:/programing/programing_created-acer/fnc-1/train_/fnc_roberta_0115_self1.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    predictions, raw_outputs = model.predict([[height, weight]])\n",
    "    \n",
    "    result = ''\n",
    "    if predictions == [0]:\n",
    "        result = 'Agree'\n",
    "    elif predictions == [1]:\n",
    "        result = 'Disagree'\n",
    "    elif predictions == [2]:\n",
    "        result = 'Discuss'\n",
    "    elif predictions == [3]:\n",
    "        result = 'Unrelated'\n",
    "    else:\n",
    "        result = 'error'\n",
    "\n",
    "\n",
    "   # result = '你的 BMI 指數為：{} {}'.format(bmi_value, get_bmi_status_description(bmi_value))\n",
    "    result_label.configure(text=result)\n",
    "'''\n",
    "def get_bmi_status_description(bmi_value):\n",
    "    if bmi_value < 18.5:\n",
    "        return '體重過輕囉，多吃點！'\n",
    "    elif bmi_value >= 18.5 and bmi_value < 24:\n",
    "        return '體重剛剛好，繼續保持！'\n",
    "    elif bmi_value >= 24 :\n",
    "        return '體重有點過重囉，少吃多運動！'\n",
    "'''\n",
    "header_label = tk.Label(window, text='', bg='white')\n",
    "header_label.pack()\n",
    "header_label = tk.Label(window, text='', bg='white')\n",
    "header_label.pack()\n",
    "header_label = tk.Label(window, text='', bg='white')\n",
    "header_label.pack()\n",
    "header_label = tk.Label(window, text='', bg='white')\n",
    "header_label.pack()\n",
    "header_label = tk.Label(window, text='Preventing One-sided News on the Social Platform Using Deep Learning and Transfer Learning Methods')\n",
    "header_label.pack()\n",
    "header_label = tk.Label(window, text='', bg='white')\n",
    "header_label.pack()\n",
    "a = tk.Label(window, bg='white',text=\"\")\n",
    "a.pack(side=tk.TOP)\n",
    "height_frame = tk.Frame(window, height=8)\n",
    "height_frame.pack(side=tk.TOP)\n",
    "height_label = tk.Label(height_frame, font=(\"Lucida Grande\", 20), text='Sentence A')\n",
    "height_label.pack(side=tk.LEFT)\n",
    "height_entry = tk.Entry(height_frame, width=70)\n",
    "height_entry.pack(side=tk.LEFT)\n",
    "a = tk.Label(window, bg='white',text=\"\")\n",
    "a.pack(side=tk.TOP)\n",
    "weight_frame = tk.Frame(window)\n",
    "weight_frame.pack(side=tk.TOP)\n",
    "weight_label = tk.Label(weight_frame, font=(\"Lucida Grande\", 20), text='Sentence B')\n",
    "weight_label.pack(side=tk.LEFT)\n",
    "weight_entry = tk.Entry(weight_frame, width=70)\n",
    "weight_entry.pack(side=tk.LEFT)\n",
    "\n",
    "result_label = tk.Label(window, bg='white')\n",
    "result_label.pack()\n",
    "\n",
    "calculate_btn = tk.Button(window, text='RUN!!!', command=calculate_bmi_number)\n",
    "calculate_btn.pack()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d29f50-c6ce-4b61-ae56-e38537ffa5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 26 03:25:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.11       Driver Version: 471.11       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8     4W /  N/A |    134MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efeadaf-c540-45f7-9f6b-4d5c3400f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0bb68-abc6-4558-872b-94febc53b7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
