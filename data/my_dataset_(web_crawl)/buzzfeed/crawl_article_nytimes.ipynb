{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0148cd3-c0de-4469-af08-6f81ca2e1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfe6ae2-435b-43b5-83d5-90cff462c8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media name</th>\n",
       "      <th>media</th>\n",
       "      <th>post</th>\n",
       "      <th>link</th>\n",
       "      <th>time</th>\n",
       "      <th>post2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>For people under guardianship, like Britney Sp...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>For people under guardianship, like Britney Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>\"I knew I would be addressing you, my beloved ...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"I knew I would be addressing you, my beloved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>When it comes to treatment with monoclonal ant...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When it comes to treatment with monoclonal ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>There’s a very American reason for why Prince ...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There’s a very American reason for why Prince ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>Scavino filed the lawsuit under his name after...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/zoetillma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scavino filed the lawsuit under his name after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>The pandemic has devoured time people wanted t...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology has made avoiding painful memories ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>The most potent instrument Swift plays on Red ...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“I don’t want to go on social media and feel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>“The idea of making a chronicle of such violen...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you still need proof that the world is buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>“The equal sentiment [we both share] is just t...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“If the projections are right, then we’re alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>BuzzFeedNews</td>\n",
       "      <td>A lawsuit by Mamie Mitchell, a script supervis...</td>\n",
       "      <td>https://l.facebook.com/l.php?u=https%3A%2F%2Fw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An American debt collection agency paid agents...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        media name         media  \\\n",
       "0    BuzzFeed News  BuzzFeedNews   \n",
       "1    BuzzFeed News  BuzzFeedNews   \n",
       "2    BuzzFeed News  BuzzFeedNews   \n",
       "3    BuzzFeed News  BuzzFeedNews   \n",
       "4    BuzzFeed News  BuzzFeedNews   \n",
       "..             ...           ...   \n",
       "472  BuzzFeed News  BuzzFeedNews   \n",
       "473  BuzzFeed News  BuzzFeedNews   \n",
       "474  BuzzFeed News  BuzzFeedNews   \n",
       "475  BuzzFeed News  BuzzFeedNews   \n",
       "476  BuzzFeed News  BuzzFeedNews   \n",
       "\n",
       "                                                  post  \\\n",
       "0    For people under guardianship, like Britney Sp...   \n",
       "1    \"I knew I would be addressing you, my beloved ...   \n",
       "2    When it comes to treatment with monoclonal ant...   \n",
       "3    There’s a very American reason for why Prince ...   \n",
       "4    Scavino filed the lawsuit under his name after...   \n",
       "..                                                 ...   \n",
       "472  The pandemic has devoured time people wanted t...   \n",
       "473  The most potent instrument Swift plays on Red ...   \n",
       "474  “The idea of making a chronicle of such violen...   \n",
       "475  “The equal sentiment [we both share] is just t...   \n",
       "476  A lawsuit by Mamie Mitchell, a script supervis...   \n",
       "\n",
       "                                                  link  time  \\\n",
       "0    https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   0.0   \n",
       "1    https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   0.0   \n",
       "2    https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "3    https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "4    https://www.buzzfeednews.com/article/zoetillma...   NaN   \n",
       "..                                                 ...   ...   \n",
       "472  https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "473  https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "474  https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "475  https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "476  https://l.facebook.com/l.php?u=https%3A%2F%2Fw...   NaN   \n",
       "\n",
       "                                                 post2  \n",
       "0    For people under guardianship, like Britney Sp...  \n",
       "1    \"I knew I would be addressing you, my beloved ...  \n",
       "2    When it comes to treatment with monoclonal ant...  \n",
       "3    There’s a very American reason for why Prince ...  \n",
       "4    Scavino filed the lawsuit under his name after...  \n",
       "..                                                 ...  \n",
       "472  Technology has made avoiding painful memories ...  \n",
       "473  “I don’t want to go on social media and feel l...  \n",
       "474  If you still need proof that the world is buil...  \n",
       "475  “If the projections are right, then we’re alre...  \n",
       "476  An American debt collection agency paid agents...  \n",
       "\n",
       "[477 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('correct.csv', index_col=0, encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca3482-cc19-4060-ac8c-90817e17b1b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "\n",
    "for i in range(len(data)):\n",
    "    print(f'{i}開始', end=' ')\n",
    "    count = 0\n",
    "    box = ''\n",
    "    url = data.loc[i,'link']   #依序i進入dataset每一則新聞\n",
    "    driver.get(url)\n",
    "    sp = soup(driver.page_source,'html.parser')\n",
    "    article = sp.find_all(class_ = \"subbuzz subbuzz-text\")\n",
    "    for a in article:\n",
    "        if count == 0:   #基於insert第一句開頭不空格\n",
    "            box += a.text\n",
    "        else:   #第二句開頭銜接要先空格\n",
    "            box += (' '+ a.text)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    print('A', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"mod-subbuzz-text-1\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('B', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text xs-mb4 xs-relative\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('C', end=' ')\n",
    "    \n",
    "    if box == '':   #跨越Facebook安全防護告警\n",
    "        url = sp.find(class_ = \"_5slv\")   #從告警頁面取出目標網址\n",
    "        driver.get(url.text)\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('D', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"mod-subbuzz-text-1\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('E', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text xs-mb4 xs-relative\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    if box == '':\n",
    "        print('None', end=' ')\n",
    "    data.loc[i,'article'] = box\n",
    "    print(f'{i}結束')\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba0a435-2984-4049-bdec-f5f2ea56fb8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9f433991dd3d>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366開始 A B C D E F G H I J K L 366結束\n",
      "367開始 A B C D E F G H I J K L 367結束\n",
      "368開始 A B C D E F G H I J K L 368結束\n",
      "369開始 A B C D E F G H I J K L 369結束\n",
      "370開始 A B C D E F G H I J K L 370結束\n",
      "371開始 A B C D E F G H I J K L 371結束\n",
      "372開始 A B C D E F G H I J K L 372結束\n",
      "373開始 A B C D E F G H I J K L 373結束\n",
      "374開始 A B C D E F G H I J K L 374結束\n",
      "375開始 A B C D E F G H I J K L 375結束\n",
      "376開始 A B C D E F G H I J K L 376結束\n",
      "377開始 A B C D E F G H I J K L 377結束\n",
      "378開始 A B C D E F G H I J K L 378結束\n",
      "379開始 A B C D E F G H I J K L 379結束\n",
      "380開始 A B C D E F G H I J K L 380結束\n",
      "381開始 A B C D E F G H I J K L 381結束\n",
      "382開始 A B C D E F G H I J K L 382結束\n",
      "383開始 A B C D E F G H I J K L 383結束\n",
      "384開始 A B C D E F G H I J K L 384結束\n",
      "385開始 A B C D E F G H I J K L None 385結束\n",
      "386開始 A B C D E F G H I J K L 386結束\n",
      "387開始 A B C D E F G H I J K L 387結束\n",
      "388開始 A B C D E F G H I J K L 388結束\n",
      "389開始 A B C D E F G H I J K L 389結束\n",
      "390開始 A B C D E F G H I J K L 390結束\n",
      "391開始 A B C D E F G H I J K L 391結束\n",
      "392開始 A B C D E F G H I J K L 392結束\n",
      "393開始 A B C D E F G H I J K L 393結束\n",
      "394開始 A B C D E F G H I J K L 394結束\n",
      "395開始 A B C D E F G H I J K L 395結束\n",
      "396開始 A B C D E F G H I J K L 396結束\n",
      "397開始 A B C D E F G H I J K L 397結束\n",
      "398開始 A B C D E F G H I J K L 398結束\n",
      "399開始 A B C D E F G H I J K L 399結束\n",
      "400開始 A B C D E F G H I J K L 400結束\n",
      "401開始 A B C D E F G H I J K L 401結束\n",
      "402開始 A B C D E F G H I J K L 402結束\n",
      "403開始 A B C D E F G H I J K L 403結束\n",
      "404開始 A B C D E F G H I J K L 404結束\n",
      "405開始 A B C D E F G H I J K L 405結束\n",
      "406開始 A B C D E F G H I J K L 406結束\n",
      "407開始 A B C D E F G H I J K L 407結束\n",
      "408開始 A B C D E F G H I J K L 408結束\n",
      "409開始 A B C D E F G H I J K L 409結束\n",
      "410開始 A B C D E F G H I J K L 410結束\n",
      "411開始 A B C D E F G H I J K L 411結束\n",
      "412開始 A B C D E F G H I J K L 412結束\n",
      "413開始 A B C D E F G H I J K L 413結束\n",
      "414開始 A B C D E F G H I J K L 414結束\n",
      "415開始 A B C D E F G H I J K L 415結束\n",
      "416開始 A B C D E F G H I J K L 416結束\n",
      "417開始 A B C D E F G H I J K L 417結束\n",
      "418開始 A B C D E F G H I J K L 418結束\n",
      "419開始 A B C D E F G H I J K L 419結束\n",
      "420開始 A B C D E F G H I J K L 420結束\n",
      "421開始 A B C D E F G H I J K L 421結束\n",
      "422開始 A B C D E F G H I J K L 422結束\n",
      "423開始 A B C D E F G H I J K L 423結束\n",
      "424開始 A B C D E F G H I J K L 424結束\n",
      "425開始 A B C D E F G H I J K L 425結束\n",
      "426開始 A B C D E F G H I J K L 426結束\n",
      "427開始 A B C D E F G H I J K L 427結束\n",
      "428開始 A B C D E F G H I J K L 428結束\n",
      "429開始 A B C D E F G H I J K L 429結束\n",
      "430開始 A B C D E F G H I J K L 430結束\n",
      "431開始 A B C D E F G H I J K L 431結束\n",
      "432開始 A B C D E F G H I J K L 432結束\n",
      "433開始 A B C D E F G H I J K L 433結束\n",
      "434開始 A B C D E F G H I J K L 434結束\n",
      "435開始 A B C D E F G H I J K L 435結束\n",
      "436開始 A B C D E F G H I J K L 436結束\n",
      "437開始 A B C D E F G H I J K L 437結束\n",
      "438開始 A B C D E F G H I J K L 438結束\n",
      "439開始 A B C D E F G H I J K L 439結束\n",
      "440開始 A B C D E F G H I J K L 440結束\n",
      "441開始 A B C D E F G H I J K L 441結束\n",
      "442開始 A B C D E F G H I J K L 442結束\n",
      "443開始 A B C D E F G H I J K L 443結束\n",
      "444開始 A B C D E F G H I J K L 444結束\n",
      "445開始 A B C D E F G H I J K L 445結束\n",
      "446開始 A B C D E F G H I J K L 446結束\n",
      "447開始 A B C D E F G H I J K L 447結束\n",
      "448開始 A B C D E F G H I J K L 448結束\n",
      "449開始 A B C D E F G H I J K L 449結束\n",
      "450開始 A B C D E F G H I J K L 450結束\n",
      "451開始 A B C D E F G H I J K L 451結束\n",
      "452開始 A B C D E F G H I J K L 452結束\n",
      "453開始 A B C D E F G H I J K L 453結束\n",
      "454開始 A B C D E F G H I J K L 454結束\n",
      "455開始 A B C D E F G H I J K L 455結束\n",
      "456開始 A B C D E F G H I J K L 456結束\n",
      "457開始 A B C D E F G H I J K L 457結束\n",
      "458開始 A B C D E F G H I J K L 458結束\n",
      "459開始 A B C D E F G H I J K L 459結束\n",
      "460開始 A B C D E F G H I J K L 460結束\n",
      "461開始 A B C D E F G H I J K L 461結束\n",
      "462開始 A B C D E F G H I J K L 462結束\n",
      "463開始 A B C D E F G H I J K L 463結束\n",
      "464開始 A B C D E F G H I J K L 464結束\n",
      "465開始 A B C D E F G H I J K L 465結束\n",
      "466開始 A B C D E F G H I J K L 466結束\n",
      "467開始 A B C D E F G H I J K L 467結束\n",
      "468開始 A B C D E F G H I J K L 468結束\n",
      "469開始 A B C D E F G H I J K L 469結束\n",
      "470開始 A B C D E F G H I J K L 470結束\n",
      "471開始 A B C D E F G H I J K L 471結束\n",
      "472開始 A B C D E F G H I J K L 472結束\n",
      "473開始 A B C D E F G H I J K L 473結束\n",
      "474開始 A B C D E F G H I J K L 474結束\n",
      "475開始 A B C D E F G H I J K L 475結束\n",
      "476開始 A B C D E F G H I J K L 476結束\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "\n",
    "for i in range(366,477):\n",
    "    print(f'{i}開始', end=' ')\n",
    "    count = 0\n",
    "    box = ''\n",
    "    url = data.loc[i,'link']   #依序i進入dataset每一則新聞\n",
    "    driver.get(url)\n",
    "    sp = soup(driver.page_source,'html.parser')\n",
    "    article = sp.find_all(class_ = \"subbuzz subbuzz-text\")\n",
    "    for a in article:\n",
    "        if count == 0:   #基於insert第一句開頭不空格\n",
    "            box += a.text\n",
    "        else:   #第二句開頭銜接要先空格\n",
    "            box += (' '+ a.text)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    print('A', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"mod-subbuzz-text-1\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('B', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text xs-mb4 xs-relative\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('C', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"js-subbuzz__title-text\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('D', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"text/x-config\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('E', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz-anchor\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('F', end=' ')\n",
    "    \n",
    "    if box == '':   #跨越Facebook安全防護告警\n",
    "        url = sp.find(class_ = \"_5slv\")   #從告警頁面取出目標網址\n",
    "        driver.get(url.text)\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('G', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"mod-subbuzz-text-1\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('H', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz subbuzz-text xs-mb4 xs-relative\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('I', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"js-subbuzz__title-text\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('J', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"text/x-config\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('K', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"subbuzz-anchor\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    print('L', end=' ')\n",
    "    \n",
    "    if box == '':\n",
    "        print('None', end=' ')\n",
    "    data.loc[i,'article'] = box\n",
    "    print(f'{i}結束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc211b3-3b07-438c-b989-e24751128f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data.loc[i,'article'] == '\\n\\n\\n\\n \\n\\n\\n\\n':\n",
    "        data = data.drop(i)\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b145776-4ff7-4b50-8ac5-681295439645",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0)\n",
    "data.loc[407,'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a2290-fcbf-43d4-90d6-73ecf25f3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4247cc4-508b-4c1c-b17a-767c464b9b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv('correct_arti.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986a8a9-1b20-4e11-abb4-dcccd9771184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.iloc[400:410,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e96aa-77e0-4528-a38a-7ba9843c9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[533,'media':'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0b30c-3f6a-424e-89b9-93a4293645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[239,'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641125c2-228a-438e-9ba0-4f289127133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a99473-22ef-43a0-811c-ac109a7b9c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966683ae-e204-41d4-82ba-3e01cd05e64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be552cb9-9fb2-49b0-bca4-298a6a64c480",
   "metadata": {},
   "source": [
    "## Lab Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7ab4b-b89a-45de-8fe0-db9b6ea39ec1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#原版：117error\n",
    "\n",
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "\n",
    "\n",
    "\n",
    "for i in range(540):\n",
    "    print(f'{i}開始', end=' ')\n",
    "    count = 0   #\n",
    "    box = ''\n",
    "    url = data.loc[i,'link']   #依序進入dataset每一則新聞\n",
    "    driver.get(url) \n",
    "    sp = soup(driver.page_source,'html.parser')\n",
    "    article = sp.find_all(class_ = \"css-axufdj evys1bk0\")\n",
    "    for a in article:\n",
    "        if count == 0:   #基於insert第一句開頭不空格\n",
    "            box += a.text\n",
    "        else:   #第二句開頭銜接要先空格\n",
    "            box += (' '+ a.text)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    if box == '':   #跨越Facebook安全防護告警\n",
    "        url = sp.find(class_ = \"_5slv\")   #從告警頁面取出目標網址\n",
    "        driver.get(url.text)\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"css-axufdj evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"live-blog-post-content css-1i6lz47 evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"css-iynevi evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    \n",
    "    data.loc[i,'article'] = box\n",
    "    print(f'{i}結束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230533e-e992-41b5-baaf-5cc7e5e9d8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "programing/programing_created-acer/fnc-1/my_dataset/wall/wall_preds.csv\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    count = 0   #\n",
    "    box = ''\n",
    "    url = data.loc[533,'link']   #依序進入dataset每一則新聞\n",
    "    driver.get(url) \n",
    "    sp = soup(driver.page_source,'html.parser')\n",
    "    article = sp.find_all(class_ = \"css-axufdj evys1bk0\")\n",
    "    for a in article:\n",
    "        if count == 0:   #基於insert第一句開頭不空格\n",
    "            box += a.text\n",
    "        else:   #第二句開頭銜接要先空格\n",
    "            box += (' '+ a.text)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"live-blog-post-content css-1i6lz47 evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"css-iynevi evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    \n",
    "    if box == '':   #跨越Facebook安全防護告警\n",
    "        url = sp.find(class_ = \"_5slv\")   #從告警頁面取出目標網址\n",
    "        driver.get(url.text)\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"css-axufdj evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "\n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"live-blog-post-content css-1i6lz47 evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "    \n",
    "    if box == '':\n",
    "        sp = soup(driver.page_source,'html.parser')\n",
    "        article = sp.find_all(class_ = \"css-iynevi evys1bk0\")\n",
    "        for a in article:\n",
    "            if count == 0:   #基於insert第一句開頭不空格\n",
    "                box += a.text\n",
    "            else:   #第二句開頭銜接要先空格\n",
    "                box += (' '+ a.text)\n",
    "            count += 1\n",
    "    count = 0\n",
    "\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c9926-2931-4c85-88c3-a527a9cec925",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "\n",
    "url = data.loc[533,'link']\n",
    "driver.get(url) \n",
    "time.sleep(5)\n",
    "sp = soup(driver.page_source,'html.parser')\n",
    "gg = sp.find(class_ = \"_5slv\")\n",
    "print(gg.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61fc47-f2cb-44ca-b1d5-e8459d3abd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[533,'post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce031f-e1ff-4ad9-b0ce-2154dd5438ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/programing/programing_created-acer/fnc-1/chromedriver_win32/chromedriver.exe')        \n",
    "\n",
    "for i in range(1):\n",
    "    box = ''\n",
    "    url = 'https://l.facebook.com/l.php?u=https%3A%2F%2Fnyti.ms%2F3F4lvXY%3Ffbclid%3DIwAR1Q96b4FQu76LYOy0owa6Fb3IeDar1LkUBxPxMnBZ3y2neUcH6gvNUzb0o&h=AT1cU0NNhemXU9lShKmso74oUt57PKXXrdBFmFfraXrwz7ircMRaIsOEZN5tKnyvYXS9JPvUJQjaahCZ9KjqsjcLGvT7FYpgJZJB0bND7gvvH4I4X1JWbOcAzOWNALZx5UJg8cmLM4TAon_zuJL4&__tn__=%2CmH-R&c[0]=AT1NZPiyursHmh92xdhID39EHwIBjFT0VbVBzBU3SjyzzN02GEMDgxmc9wamGHbgvJFN7Oib74iQVNW5bCYlx22wkrSdI3zWv-gV6SZrCxnJl_LCMS8Zm4GeYw0X3QpTqrblX3MvbOs8ra2SDIpqnZCvnuPnWesR8rOTWhgC9Ro5NfQC'\n",
    "    driver.get(url) \n",
    "    sp = soup(driver.page_source,'html.parser')\n",
    "    article = sp.find_all(class_ = \"css-axufdj evys1bk0\")\n",
    "    for a in article:\n",
    "        box += (' '+ a.text)\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070852f3-172d-449d-87e1-fb34056239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nytimes__.csv', index_col=0,encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af872a-3405-4831-bc76-62d4c84c8d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
